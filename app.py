import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from wordcloud import WordCloud
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from data_manager import load_data, load_model, preprocess_missing_values, delete_invalid_ratings, preprocess_duplicate, merge_data, build_tfidf    
import altair as alt
import pickle
import os
import joblib

st.set_page_config(page_title="Anime Analytics Dashboard", layout="wide")

# ============================
# 1. LOAD DATA
# ============================
rating, anime = load_data()
model = load_model()
# ============================
# 1. HEADER
# ============================
st.title("üéå Anime Analytics Dashboard")
st.caption("‚ú® Ph√¢n t√≠ch, tr·ª±c quan h√≥a v√† g·ª£i √Ω anime d·ª±a tr√™n d·ªØ li·ªáu ng∆∞·ªùi d√πng")
# ============================
# 2. L√ÄM S·∫†CH D·ªÆ LI·ªÜU
# ============================
st.header("üõ†Ô∏è L√†m s·∫°ch v√† chu·∫©n b·ªã d·ªØ li·ªáu")
st.subheader("1. Missing Values")
colA, colB = st.columns(2)
with colA:
    st.subheader("üîç Thi·∫øu d·ªØ li·ªáu - Anime")
    missing_anime = anime.isna().sum()
    missing_anime = pd.DataFrame({"T√™n c·ªôt": anime.columns, "S·ªë l∆∞·ª£ng thi·∫øu": missing_anime.values})
    st.dataframe(missing_anime, width="stretch")
with colB:
    st.subheader("üîç Thi·∫øu d·ªØ li·ªáu - Rating")
    missing_rating = rating.isna().sum()
    missing_rating = pd.DataFrame({"T√™n c·ªôt": rating.columns, "S·ªë l∆∞·ª£ng thi·∫øu": missing_rating.values})
    st.dataframe(missing_rating, width="stretch")
## X·ª≠ l√Ω d·ªØ li·ªáu
anime = preprocess_missing_values(anime)
after_missing = pd.DataFrame({"T√™n c·ªôt": anime.columns, "S·ªë l∆∞·ª£ng thi·∫øu": anime.isna().sum().values})

st.subheader("‚öôÔ∏è Sau khi x·ª≠ l√Ω Missing values")
st.dataframe(after_missing, width="stretch")

# #l·ªçai b·ªè d·ªØ li·ªáu tr√πng l·∫∑p
st.subheader("2. Lo·∫°i b·ªè d·ªØ li·ªáu tr√πng l·∫∑p")
before_dup_anime = len(anime)
anime_clean,rating_clean = preprocess_duplicate(anime,rating)
after_dup_anime = len(anime_clean)
st.success(f"‚úî ƒê√£ lo·∫°i {before_dup_anime - after_dup_anime} d√≤ng tr√πng trong anime.")

# # Invalid Ratings
st.subheader("3. Chu·∫©n h√≥a d·ªØ li·ªáu  Rating")
st.write("Chu·∫•n h√≥a Item-based mean centering tr√™n d·ªØ li·ªáu Rating")
pivot_sparse = model["pivot_sparse"]   # csr_matrix (item √ó user)
item_names   = model["item_names"]     # list anime names
user_index   = model["user_index"]     # dict: user_id -> col index
knn          = model.get("knn", None)  # n·∫øu b·∫°n c√≥ l∆∞u knn
st.success(f"‚úî D·ªØ li·ªáu Rating ƒë√£ ƒë∆∞·ª£c chu·∫©n h√≥a.")
user_ids = list(user_index.keys())

rows, cols = pivot_sparse.nonzero()

if len(rows) > 0:
    sample_size = min(30, len(rows))
    sample_idx = np.random.choice(len(rows), sample_size, replace=False)

    nnz_data = {
        "Anime": [item_names[rows[i]] for i in sample_idx],
        "User":  [user_ids[cols[i]] for i in sample_idx],
        "Rating": pivot_sparse.data[sample_idx],
    }

    df_nnz = pd.DataFrame(nnz_data)
    st.dataframe(df_nnz, use_container_width=True)
else:
    st.warning("Sparse matrix has no non-zero entries!")

st.divider()


st.subheader("4. Vector h√≥a d·ªØ li·ªáu IF-IDF")
# # T·∫°o vƒÉn b·∫£n k·∫øt h·ª£p (genre + type)
# # TF-IDF vectorizer
tfidf, tfidf_matrix = build_tfidf(anime_clean)
sample_tfidf = pd.DataFrame(
    tfidf_matrix[:10, :20].toarray(),
    columns=tfidf.get_feature_names_out()[:20],
    index=anime_clean["name"][:10]
)
st.dataframe(sample_tfidf)
# # # ============================
# # 3. G·ªòP D·ªÆ LI·ªÜU
# # ============================

# merged = merge_data(rating_clean, anime_clean)
# st.dataframe(merged.head(), width="stretch")

# # ============================
# # 4. DASHBOARD
# # ============================
st.header("üìä Ph√¢n t√≠ch & Tr·ª±c quan h√≥a")

tab1, tab2, tab3, tab4 = st.tabs([
    "üìà Ph√¢n b·ªë Rating",
    "üèÜ Top Anime",
    "üé≠ Genre v√† Type",
    "üî• Heatmap"
])

# ============================
# TAB 1: PH√ÇN B·ªê RATING
# ============================
with tab1:
    st.subheader("üìà Histogram ph√¢n b·ªë Rating anime")
    #histogram ph√¢n b·ªë rating anime
    chart = (
        alt.Chart(anime_clean)
        .mark_bar(cornerRadiusTopLeft=6, cornerRadiusTopRight=6)
        .encode(
            alt.X("rating:Q", bin=alt.Bin(maxbins=30), title="Rating"),
            alt.Y("count():Q", title="S·ªë l∆∞·ª£ng Anime"),
            tooltip=[alt.Tooltip("count():Q", title="S·ªë l∆∞·ª£ng Anime")]
        )
        .properties(width="container", height=400)
        .configure_view(strokeWidth=0)
        .configure_axis(grid=False)
    )
    st.altair_chart(chart, width="stretch")
    
    
    

# # ============================
# # TAB 2: TOP ANIME
# # ============================
with tab2:
    st.subheader("üèÜ Top Anime theo Rating trung b√¨nh")

    top_n = st.slider("Ch·ªçn s·ªë l∆∞·ª£ng top:", 5, 30, 15)

    top_anime = (
        anime_clean.sort_values("rating", ascending=False)
        .head(top_n)
        .reset_index(drop=True)
    )
    order = top_anime["name"].tolist()
    st.dataframe(top_anime, width="stretch")
    
#     # M·ªói bar m·ªôt m√†u
    top_anime["color_id"] = top_anime.index.astype(str)
    order = top_anime["name"].tolist()
    # Bi·ªÉu ƒë·ªì ch√≠nh
    bars = (
    alt.Chart(top_anime)
    .mark_bar(cornerRadiusTopLeft=6, cornerRadiusTopRight=6)
    .encode(
        x=alt.X("name:N", sort=order),
        y=alt.Y("rating:Q"),
        color=alt.Color("color_id:N", legend=None)
    )
)

    text = (
        alt.Chart(top_anime)
        .mark_text(align="center", baseline="bottom", dy=-4)
        .encode(
            x=alt.X("name:N", sort=order),
            y="rating:Q",
            text="rating:Q"
        )
    )

    # Layer + config
    final_chart = (
        (bars + text)
        .properties(width="container", height=450)
        .configure_view(strokeWidth=0)
        .configure_axis(grid=False)
    )

    st.altair_chart(final_chart, width="stretch")
    
    
    st.subheader("üèÖ Top Anime theo S·ªë l∆∞·ª£ng th√†nh vi√™n")
    top_members = (
        anime_clean.sort_values("members", ascending=False)
        .head(top_n)
        .reset_index(drop=True)
    )
    st.dataframe(top_members, width="stretch")
    # M·ªói bar m·ªôt m√†u
    top_members["color_id"] = top_members.index.astype(str)
    order_members = top_members["name"].tolist()
    # Bi·ªÉu ƒë·ªì ch√≠nh
    bars_members = (
    alt.Chart(top_members)
    .mark_bar(cornerRadiusTopLeft=6, cornerRadiusTopRight=6)
    .encode(
        x=alt.X("name:N", sort=order_members),
        y=alt.Y("members:Q"),
        color=alt.Color("color_id:N", legend=None)
    )
    )
    text_members = (
        alt.Chart(top_members)
        .mark_text(align="center", baseline="bottom", dy=-4)
        .encode(
            x=alt.X("name:N", sort=order_members),
            y="members:Q",
            text="members:Q"
        )
    )
    # Layer + config
    final_chart_members = (
        (bars_members + text_members)
        .properties(width="container", height=450)
        .configure_view(strokeWidth=0)
        .configure_axis(grid=False)
    )
    st.altair_chart(final_chart_members, width="stretch")
    

# # ============================
# # TAB 3: PH√ÇN T√çCH GENRE
# # ============================
with tab3:
    st.subheader("üé≠ Ph√¢n t√≠ch type Anime")
    type_count = anime_clean["type"].value_counts().reset_index()
    type_count.columns = ["type", "count"]
    type_row = type_count.set_index("type").T
    st.dataframe(type_row, width="stretch")
    st.subheader("üìä Ph√¢n b·ªë type Anime")
    #pie chart hi·ªán th·ªã t·ªâ l·ªá t·ª´ng type
    chart_pie = (
        alt.Chart(type_count)
        .mark_arc(innerRadius=50)
        .encode(
            theta=alt.Theta(field="count", type="quantitative"),
            color=alt.Color(field="type", type="nominal"),
            tooltip=[alt.Tooltip("type:N", title="Type"), alt.Tooltip("count:Q", title="S·ªë l∆∞·ª£ng")]
        )
        .properties(width="container", height=400)
    )


    st.altair_chart(chart_pie, width="stretch")
    st.subheader("üìä Ph√¢n b·ªë type Anime (Altair Bar Chart)")
    chart_bar_type = (
        alt.Chart(type_count)
        .mark_bar(cornerRadiusTopLeft=6, cornerRadiusTopRight=6)
        .encode(
            x=alt.X("type:N", sort="-y", title="Type"),
            y=alt.Y("count:Q", title="T·∫ßn su·∫•t"),
            color=alt.Color("type:N", legend=None)
        )
        .properties(width="container", height=400)
    )
    text = (
        alt.Chart(type_count)
        .mark_text(align="center", baseline="bottom", dy=-4)
        .encode(
            x=alt.X("type:N", sort="-y"),
            y="count:Q",
            text="count:Q"
        )
    )
    chart_bar_type = chart_bar_type + text
    st.altair_chart(chart_bar_type, width="stretch")
    st.subheader("üé≠ T·∫ßn su·∫•t th·ªÉ lo·∫°i Anime")
    # T√°ch t·ª´ng genre
    genre_exploded = anime_clean["genre"].dropna().str.split(", ").explode()
    # ƒê·∫øm t·∫ßn su·∫•t
    genre_count = genre_exploded.value_counts().reset_index()
    genre_count.columns = ["genre", "count"]
    # Chuy·ªÉn th√†nh format h√†ng ngang
    genre_row = genre_count.set_index("genre").T

    st.dataframe(genre_row, width="stretch")
    st.subheader("üìä Ph√¢n b·ªë th·ªÉ lo·∫°i Anime (Altair Bar Chart)")

    chart_bar = (
        alt.Chart(genre_count)
        .mark_bar(cornerRadiusTopLeft=6, cornerRadiusTopRight=6)
        .encode(
            x=alt.X("genre:N", sort="-y", title="Th·ªÉ lo·∫°i"),
            y=alt.Y("count:Q", title="T·∫ßn su·∫•t"),
            color=alt.Color("genre:N", legend=None)
        )
        .properties(width="container", height=400)
    )

    st.altair_chart(chart_bar, width="stretch")
    st.subheader("‚òÅÔ∏è WordCloud th·ªÉ lo·∫°i Anime")
    # T·∫°o WordCloud
    genre_text = " ".join(genre_exploded.tolist())
    wordcloud = WordCloud(width=800, height=400, background_color="white").generate(genre_text)
    # Hi·ªÉn th·ªã WordCloud
    fig, ax = plt.subplots(figsize=(10, 5))
    ax.imshow(wordcloud, interpolation="bilinear")
    ax.axis("off")
    st.pyplot(fig)
    


# # ============================
# # TAB 4: HEATMAP
# # ============================
@st.cache_resource
def load_joined_data():
    joined = pd.read_parquet("joined.parquet")
    joined.rename(columns={"rating_x":"user_rating","rating_y":"anime_avg_rating","name":"anime_name"},inplace=True)
    return joined

with tab4:
    joined = load_joined_data()
    corr = joined[["user_rating", "anime_avg_rating", "members"]].corr()
    st.subheader("üî• Heatmap ma tr·∫≠n t∆∞∆°ng quan")
    fig, ax = plt.subplots(figsize=(5, 3))
    sns.heatmap(corr, annot=True, fmt=".2f", cmap="coolwarm", ax=ax)
    st.pyplot(fig)
